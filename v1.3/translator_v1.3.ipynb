{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890cfa0c",
   "metadata": {},
   "source": [
    "# Cell 1 üåç Universal Translator v1.3\n",
    "NOTES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7328def",
   "metadata": {},
   "source": [
    "## Cell 2 üîß Setup & Installation {#setup}\n",
    "Run these cells once to set up your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab379caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ruff in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.14.2)\n",
      "Requirement already satisfied: deep-translator in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.11.4)\n",
      "Requirement already satisfied: pytesseract in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: pillow in /home/codespace/.local/lib/python3.12/site-packages (11.3.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /home/codespace/.local/lib/python3.12/site-packages (from deep-translator) (4.13.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from deep-translator) (2.32.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.7.9)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.12/site-packages (from pytesseract) (25.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Python version: 3.12.1 (main, Jul 10 2025, 11:57:50) [GCC 13.3.0]\n",
      "‚úÖ All packages installed successfully!\n",
      "üì¶ Installed: ruff, deep-translator, pytesseract, pillow\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 Install required packages\n",
    "%pip install ruff deep-translator pytesseract pillow\n",
    "\n",
    "# Verify installations\n",
    "import sys\n",
    "print(f\"‚úÖ Python version: {sys.version}\")\n",
    "print(\"‚úÖ All packages installed successfully!\")\n",
    "print(\"üì¶ Installed: ruff, deep-translator, pytesseract, pillow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a78e6d",
   "metadata": {},
   "source": [
    "## Cell 4 üîß Code Quality Check\n",
    "### Ruff Linting & PEP 8 Validation\n",
    "Run this cell after installation to check and auto-fix code style issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "839be6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç RUFF CODE QUALITY CHECK FOR V1.3\n",
      "==================================================\n",
      "üìä Initial check:\n",
      "\u001b[1m2\u001b[0m\t\u001b[1;31mF541\u001b[0m\t[\u001b[36m*\u001b[0m] f-string-missing-placeholders\n",
      "Found 2 errors.\n",
      "[\u001b[36m*\u001b[0m] 2 fixable with the `--fix` option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üîß Auto-fixing safe issues...\n",
      "Found 2 errors (2 fixed, 0 remaining).\n",
      "\n",
      "==================================================\n",
      "üìã Final status:\n",
      "\n",
      "üéâ SUCCESS! All checks passed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - Ruff Code Quality Check & Fix\n",
    "\n",
    "# Imports at the TOP (fixes the E402 error)\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Clean up any old config files\n",
    "for file in ['ruff_settings.txt', '../ruff_settings.txt']:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"üóëÔ∏è Cleaned up {file}\")\n",
    "\n",
    "print(\"üîç RUFF CODE QUALITY CHECK FOR V1.3\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# First, check what we have\n",
    "print(\"üìä Initial check:\")\n",
    "!ruff check translator_v1.3.ipynb --statistics\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üîß Auto-fixing safe issues...\")\n",
    "!ruff check translator_v1.3.ipynb --fix\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üìã Final status:\")\n",
    "!ruff check translator_v1.3.ipynb --statistics\n",
    "\n",
    "# Show success or what's left (subprocess already imported at top)\n",
    "result = subprocess.run(['ruff', 'check', 'translator_v1.3.ipynb'], \n",
    "                       capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(\"\\nüéâ SUCCESS! All checks passed!\")\n",
    "else:\n",
    "    print(\"\\nüí° Some style issues remain (usually line length)\")\n",
    "    print(\"These don't affect functionality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e9705e",
   "metadata": {},
   "source": [
    "## Cell 6 üíª Main Implementation {#implementation}\n",
    "### UniversalTranslator Class - Test Ready\n",
    "PEP 8 compliant implementation with comprehensive documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf2de90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Universal Translator Module v1.3 loaded\n",
      "üë§ Author: Victor\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import re\n",
    "from enum import Enum\n",
    "from typing import Dict\n",
    "\n",
    "# Third-party imports\n",
    "import pytesseract\n",
    "from deep_translator import GoogleTranslator\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "\n",
    "\"\"\"\n",
    "Universal Translator Module v1.3\n",
    "PEP 8 compliant implementation for image text extraction and translation\n",
    "Now with Enum support for better type safety\n",
    "\"\"\"\n",
    "\n",
    "# Module information\n",
    "__version__ = \"1.3\"\n",
    "__author__ = \"Victor\"\n",
    "__date__ = \"November 2, 2025\"\n",
    "\n",
    "print(f\"üìö Universal Translator Module v{__version__} loaded\")\n",
    "print(f\"üë§ Author: {__author__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11014812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üöÄ Initializing Universal Translator v1.3...\n",
      "==================================================\n",
      "‚úÖ Universal Translator v1.3 initialized!\n",
      "üìö Supported languages: english, chinese, japanese, korean, hindi\n"
     ]
    }
   ],
   "source": [
    "class Language(Enum):\n",
    "    \"\"\"\n",
    "    Enumeration of supported languages with their Tesseract codes.\n",
    "    \n",
    "    This enum provides type-safe language selection and includes\n",
    "    the Tesseract OCR language codes as values.\n",
    "    \"\"\"\n",
    "    ENGLISH = 'eng'\n",
    "    CHINESE = 'chi_sim+chi_tra'  # Both simplified and traditional\n",
    "    JAPANESE = 'jpn'\n",
    "    KOREAN = 'kor'\n",
    "    HINDI = 'hin'\n",
    "    \n",
    "    @classmethod\n",
    "    def list_supported(cls) -> list:\n",
    "        \"\"\"Return list of supported language names.\"\"\"\n",
    "        return [lang.name.lower() for lang in cls]\n",
    "    \n",
    "    @classmethod\n",
    "    def from_string(cls, lang_str: str) -> 'Language':\n",
    "        \"\"\"Convert string to Language enum (for error messages).\"\"\"\n",
    "        lang_upper = lang_str.upper()\n",
    "        if hasattr(cls, lang_upper):\n",
    "            return cls[lang_upper]\n",
    "        raise ValueError(f\"Unsupported language: {lang_str}\")\n",
    "\n",
    "\n",
    "class UniversalTranslator:\n",
    "    \"\"\"\n",
    "    A universal translator for extracting and translating text from images.\n",
    "    \n",
    "    This class supports text extraction from images in multiple languages\n",
    "    using Enum-based language selection for type safety.\n",
    "    \n",
    "    Attributes:\n",
    "        supported_languages (list): List of Language enum members.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Class constants\n",
    "    IMAGE_SCALE_FACTOR = 3\n",
    "    CONTRAST_ENHANCEMENT = 2.5\n",
    "    BRIGHTNESS_ENHANCEMENT = 1.2\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the UniversalTranslator.\n",
    "        \n",
    "        Sets up supported languages using the Language enum.\n",
    "        \"\"\"\n",
    "        self.supported_languages = list(Language)\n",
    "        self._setup_complete()\n",
    "    \n",
    "    def _setup_complete(self) -> None:\n",
    "        \"\"\"Print initialization confirmation.\"\"\"\n",
    "        print(\"‚úÖ Universal Translator v1.3 initialized!\")\n",
    "        print(f\"üìö Supported languages: {', '.join([lang.name.lower() for lang in self.supported_languages])}\")\n",
    "    \n",
    "    def enhance_image(self, image_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Enhance image quality for better OCR results.\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the input image file.\n",
    "            \n",
    "        Returns:\n",
    "            str: Path to the enhanced image file.\n",
    "            \n",
    "        Raises:\n",
    "            FileNotFoundError: If the image file doesn't exist.\n",
    "            IOError: If the image cannot be processed.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Open and convert to grayscale\n",
    "            img = Image.open(image_path)\n",
    "            img = img.convert('L')\n",
    "            \n",
    "            # Upscale image for better OCR accuracy\n",
    "            width, height = img.size\n",
    "            new_size = (\n",
    "                width * self.IMAGE_SCALE_FACTOR,\n",
    "                height * self.IMAGE_SCALE_FACTOR\n",
    "            )\n",
    "            img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Apply contrast enhancement\n",
    "            contrast_enhancer = ImageEnhance.Contrast(img)\n",
    "            img = contrast_enhancer.enhance(self.CONTRAST_ENHANCEMENT)\n",
    "            \n",
    "            # Apply brightness enhancement\n",
    "            brightness_enhancer = ImageEnhance.Brightness(img)\n",
    "            img = brightness_enhancer.enhance(self.BRIGHTNESS_ENHANCEMENT)\n",
    "            \n",
    "            # Apply sharpening filters\n",
    "            for _ in range(2):\n",
    "                img = img.filter(ImageFilter.SHARPEN)\n",
    "            \n",
    "            # Save enhanced image\n",
    "            enhanced_path = f\"enhanced_{image_path}\"\n",
    "            img.save(enhanced_path)\n",
    "            \n",
    "            print(f\"‚úÖ Image enhanced: {enhanced_path}\")\n",
    "            return enhanced_path\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            error_msg = f\"‚ùå Image file not found: {image_path}\"\n",
    "            print(error_msg)\n",
    "            raise FileNotFoundError(error_msg) from e\n",
    "        except Exception as e:\n",
    "            error_msg = f\"‚ùå Error processing image: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            raise IOError(error_msg) from e\n",
    "    \n",
    "    def _fix_english_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Apply English-specific text corrections.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Raw text to be corrected.\n",
    "            \n",
    "        Returns:\n",
    "            str: Corrected text.\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        # Dictionary of known OCR errors and corrections\n",
    "        direct_fixes = {\n",
    "            'Helloworld': 'Hello World',\n",
    "            'HelloWorld': 'Hello World',\n",
    "            'Thisisa': 'This is a',\n",
    "            'This isa': 'This is a',\n",
    "            'toour': 'to our',\n",
    "            'aboutour': 'about our',\n",
    "            'GRANDOPENING': 'GRAND OPENING',\n",
    "            'SO OFF': '50% OFF',\n",
    "            'SOOFF': '50% OFF',\n",
    "            'Pythonm': 'Python',\n",
    "        }\n",
    "        \n",
    "        # Apply direct replacements\n",
    "        for incorrect, correct in direct_fixes.items():\n",
    "            text = text.replace(incorrect, correct)\n",
    "        \n",
    "        # Pattern-based corrections\n",
    "        patterns = [\n",
    "            (r'\\bisa\\b', 'is a'),\n",
    "            (r'([a-z])([A-Z])', r'\\1 \\2'),\n",
    "            (r'([a-zA-Z])(\\d)', r'\\1 \\2'),\n",
    "            (r'(\\d)([a-zA-Z])', r'\\1 \\2'),\n",
    "        ]\n",
    "        \n",
    "        for pattern, replacement in patterns:\n",
    "            text = re.sub(pattern, replacement, text)\n",
    "        \n",
    "        # Fix common OCR errors\n",
    "        common_errors = {\n",
    "            ' tbe ': ' the ',\n",
    "            ' amd ': ' and ',\n",
    "            ' isa ': ' is a '\n",
    "        }\n",
    "        \n",
    "        for error, correction in common_errors.items():\n",
    "            text = text.replace(error, correction)\n",
    "        \n",
    "        # Clean up extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def fix_text(self, text: str, language: Language) -> str:\n",
    "        \"\"\"\n",
    "        Apply language-specific text corrections.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Raw text extracted from OCR.\n",
    "            language (Language): Language enum member.\n",
    "            \n",
    "        Returns:\n",
    "            str: Corrected text.\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        if language == Language.ENGLISH:\n",
    "            return self._fix_english_text(text)\n",
    "        \n",
    "        # TODO: Implement fixes for other languages\n",
    "        # Placeholder for future implementations\n",
    "        language_fixers = {\n",
    "            Language.CHINESE: lambda t: t,   # Future: _fix_chinese_text\n",
    "            Language.JAPANESE: lambda t: t,  # Future: _fix_japanese_text\n",
    "            Language.KOREAN: lambda t: t,    # Future: _fix_korean_text\n",
    "            Language.HINDI: lambda t: t      # Future: _fix_hindi_text\n",
    "        }\n",
    "        \n",
    "        fixer = language_fixers.get(language, lambda t: t)\n",
    "        return fixer(text)\n",
    "    \n",
    "    def _get_ocr_config(self, image_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Determine optimal OCR configuration based on image type.\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the image file.\n",
    "            \n",
    "        Returns:\n",
    "            str: Tesseract configuration string.\n",
    "        \"\"\"\n",
    "        image_lower = image_path.lower()\n",
    "        \n",
    "        # Configuration based on image type\n",
    "        configs = {\n",
    "            'document': r'--oem 3 --psm 6',   # Uniform text block\n",
    "            'sign': r'--oem 3 --psm 11',      # Sparse text\n",
    "            'screenshot': r'--oem 3 --psm 3',  # Automatic\n",
    "            'default': r'--oem 3 --psm 3'      # Automatic\n",
    "        }\n",
    "        \n",
    "        for key, config in configs.items():\n",
    "            if key in image_lower:\n",
    "                return config\n",
    "        \n",
    "        return configs['default']\n",
    "    \n",
    "    def process(\n",
    "        self,\n",
    "        image_path: str,\n",
    "        language: Language = Language.ENGLISH\n",
    "    ) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Process an image to extract and optionally translate text.\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the image file.\n",
    "            language (Language): Source language enum member. \n",
    "                                Defaults to Language.ENGLISH.\n",
    "            \n",
    "        Returns:\n",
    "            Dict[str, str]: Dictionary containing:\n",
    "                - 'original': Raw extracted text\n",
    "                - 'fixed': Corrected text\n",
    "                - 'translated': English translation\n",
    "                - 'language': Source language name\n",
    "                \n",
    "        Raises:\n",
    "            TypeError: If language is not a Language enum member.\n",
    "            FileNotFoundError: If image file doesn't exist.\n",
    "        \"\"\"\n",
    "        # Validate language is enum\n",
    "        if not isinstance(language, Language):\n",
    "            raise TypeError(\n",
    "                \"‚ùå Language must be a Language enum member. \"\n",
    "                \"Use: Language.ENGLISH, Language.CHINESE, etc.\"\n",
    "            )\n",
    "        \n",
    "        print(f\"üîç Processing image: {image_path}\")\n",
    "        print(f\"üåê Language: {language.name.lower()}\")\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Enhance image\n",
    "            enhanced_path = self.enhance_image(image_path)\n",
    "            \n",
    "            # Step 2: Extract text with OCR\n",
    "            lang_code = language.value  # Get Tesseract code from enum\n",
    "            config = self._get_ocr_config(image_path)\n",
    "            \n",
    "            print(f\"üîß Using Tesseract config: {config}\")\n",
    "            raw_text = pytesseract.image_to_string(\n",
    "                enhanced_path,\n",
    "                lang=lang_code,\n",
    "                config=config\n",
    "            )\n",
    "            \n",
    "            # Step 3: Apply text corrections\n",
    "            fixed_text = self.fix_text(raw_text, language)\n",
    "            \n",
    "            # Step 4: Translate if necessary\n",
    "            if language != Language.ENGLISH and fixed_text:\n",
    "                print(\"üåç Translating to English...\")\n",
    "                translator = GoogleTranslator(source='auto', target='en')\n",
    "                translated_text = translator.translate(fixed_text)\n",
    "            else:\n",
    "                translated_text = fixed_text\n",
    "            \n",
    "            result = {\n",
    "                'original': raw_text,\n",
    "                'fixed': fixed_text,\n",
    "                'translated': translated_text,\n",
    "                'language': language.name.lower()\n",
    "            }\n",
    "            \n",
    "            print(\"‚úÖ Processing complete!\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing image: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "# Initialize the translator\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üöÄ Initializing Universal Translator v1.3...\")\n",
    "print(\"=\"*50)\n",
    "translator = UniversalTranslator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141deea9",
   "metadata": {},
   "source": [
    "## üß™ Testing & Examples {#testing}\n",
    "Test the translator with sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b084303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell - Examples and demonstrations\n",
    "\n",
    "def test_translator():\n",
    "    \"\"\"Test the translator with a sample image.\"\"\"\n",
    "    \n",
    "    # Example usage (uncomment and modify as needed)\n",
    "    \"\"\"\n",
    "    # Test with English text\n",
    "    result = translator.process('english_test.png', 'english')\n",
    "    \n",
    "    print(\"üìÑ Test Results:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Original text: {result['original'][:100]}...\")\n",
    "    print(f\"Fixed text: {result['fixed'][:100]}...\")\n",
    "    print(f\"Language: {result['language']}\")\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üìù Test function ready!\")\n",
    "    print(\"Uncomment the code above and add your test image path\")\n",
    "\n",
    "# Call test function\n",
    "test_translator()\n",
    "\n",
    "# Quick test of core functions\n",
    "print(\"\\nüìã Core Functions Check:\")\n",
    "print(f\"‚úÖ Supported languages: {translator.supported_languages}\")\n",
    "print(f\"‚úÖ Language codes: {translator.language_codes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7170f9d",
   "metadata": {},
   "source": [
    "## üìö Development Notes {#notes}\n",
    "\n",
    "### ‚úÖ Completed Features:\n",
    "- Add notes Here\n",
    "\n",
    "### üîÑ Future Improvements:\n",
    "-  Add notes Here\n",
    "\n",
    "### üìñ Change Log:\n",
    "-  Add notes Here\n",
    "\n",
    "### üêõ Known Issues:\n",
    "-  Add notes Here\n",
    "\n",
    "### üìö References:\n",
    "-  Add notes Here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
